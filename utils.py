"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏ –≤–∏–¥–µ–æ
"""

import cv2
import numpy as np
import os
from pathlib import Path
import matplotlib.pyplot as plt
from skimage import color
import torch


def is_grayscale_video(video_path, sample_frames=10):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –≤–∏–¥–µ–æ —á–µ—Ä–Ω–æ-–±–µ–ª—ã–º
    
    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ —Ñ–∞–π–ª—É
        sample_frames: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    
    Returns:
        bool: True –µ—Å–ª–∏ –≤–∏–¥–µ–æ —á–µ—Ä–Ω–æ-–±–µ–ª–æ–µ
    """
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_step = max(1, total_frames // sample_frames)
    
    grayscale_count = 0
    frames_checked = 0
    
    for i in range(0, total_frames, frame_step):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        
        if not ret:
            break
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–¥–∏–Ω–∞–∫–æ–≤—ã –ª–∏ –≤—Å–µ –∫–∞–Ω–∞–ª—ã —Ü–≤–µ—Ç–∞
        b, g, r = cv2.split(frame)
        
        # –ï—Å–ª–∏ –∫–∞–Ω–∞–ª—ã –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ, —Å—á–∏—Ç–∞–µ–º –∫–∞–¥—Ä —á–µ—Ä–Ω–æ-–±–µ–ª—ã–º
        if np.allclose(b, g, atol=5) and np.allclose(g, r, atol=5):
            grayscale_count += 1
        
        frames_checked += 1
        
        if frames_checked >= sample_frames:
            break
    
    cap.release()
    
    # –°—á–∏—Ç–∞–µ–º –≤–∏–¥–µ–æ —á–µ—Ä–Ω–æ-–±–µ–ª—ã–º, –µ—Å–ª–∏ –±–æ–ª—å—à–µ 80% –∫–∞–¥—Ä–æ–≤ —á–µ—Ä–Ω–æ-–±–µ–ª—ã–µ
    return (grayscale_count / frames_checked) > 0.8


def create_comparison_image(original_frame, colorized_frame, output_path=None):
    """
    –°–æ–∑–¥–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏ –∫–æ–ª–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–æ–≤
    
    Args:
        original_frame: –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–¥—Ä
        colorized_frame: –∫–æ–ª–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–∞–¥—Ä
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    Returns:
        numpy.ndarray: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    """
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
    h, w = original_frame.shape[:2]
    colorized_resized = cv2.resize(colorized_frame, (w, h))
    
    # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison = np.hstack([original_frame, colorized_resized])
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.putText(comparison, 'Original', (10, 30), font, 1, (255, 255, 255), 2)
    cv2.putText(comparison, 'Colorized', (w + 10, 30), font, 1, (255, 255, 255), 2)
    
    if output_path:
        cv2.imwrite(output_path, comparison)
    
    return comparison


def extract_sample_frames(video_path, output_dir, num_frames=5):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—Ä–∞–∑—Ü—ã –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
    
    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤
        num_frames: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
    """
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_step = total_frames // (num_frames + 1)  # +1 —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞
    
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    extracted_frames = []
    
    for i in range(1, num_frames + 1):
        frame_pos = i * frame_step
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
        ret, frame = cap.read()
        
        if ret:
            frame_path = output_dir / f"frame_{i:03d}.jpg"
            cv2.imwrite(str(frame_path), frame)
            extracted_frames.append(str(frame_path))
            print(f"–ò–∑–≤–ª–µ—á–µ–Ω –∫–∞–¥—Ä {i}: {frame_path}")
    
    cap.release()
    return extracted_frames


def get_video_info(video_path):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ —Ñ–∞–π–ª–µ
    
    Args:
        video_path: –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ
    
    Returns:
        dict: —Å–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤–∏–¥–µ–æ
    """
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {video_path}")
    
    info = {
        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
        'fps': cap.get(cv2.CAP_PROP_FPS),
        'frame_count': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),
        'duration': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / cap.get(cv2.CAP_PROP_FPS),
        'file_size': os.path.getsize(video_path) / (1024 * 1024)  # MB
    }
    
    cap.release()
    return info


def create_preview_grid(frames, output_path, grid_size=(2, 3)):
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–µ—Ç–∫—É –∏–∑ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
    
    Args:
        frames: —Å–ø–∏—Å–æ–∫ –∫–∞–¥—Ä–æ–≤ (numpy arrays)
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        grid_size: —Ä–∞–∑–º–µ—Ä —Å–µ—Ç–∫–∏ (rows, cols)
    """
    rows, cols = grid_size
    
    if len(frames) > rows * cols:
        frames = frames[:rows * cols]
    
    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤ –¥–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ
    target_height, target_width = 200, 300
    resized_frames = []
    
    for frame in frames:
        resized = cv2.resize(frame, (target_width, target_height))
        resized_frames.append(resized)
    
    # –î–æ–ø–æ–ª–Ω—è–µ–º —á–µ—Ä–Ω—ã–º–∏ –∫–∞–¥—Ä–∞–º–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    while len(resized_frames) < rows * cols:
        black_frame = np.zeros((target_height, target_width, 3), dtype=np.uint8)
        resized_frames.append(black_frame)
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç–∫—É
    grid_rows = []
    for i in range(rows):
        row_frames = resized_frames[i * cols:(i + 1) * cols]
        row = np.hstack(row_frames)
        grid_rows.append(row)
    
    grid = np.vstack(grid_rows)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    cv2.imwrite(output_path, grid)
    print(f"–°–µ—Ç–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {output_path}")


def check_system_resources():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
    
    Returns:
        dict: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    """
    import psutil
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU
    gpu_available = torch.cuda.is_available()
    gpu_memory = 0
    gpu_name = "–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω"
    
    if gpu_available:
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)  # GB
        gpu_name = torch.cuda.get_device_name(0)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º RAM
    ram = psutil.virtual_memory()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º CPU
    cpu_count = psutil.cpu_count()
    cpu_freq = psutil.cpu_freq()
    
    info = {
        'gpu_available': gpu_available,
        'gpu_name': gpu_name,
        'gpu_memory_gb': gpu_memory,
        'ram_total_gb': ram.total / (1024**3),
        'ram_available_gb': ram.available / (1024**3),
        'cpu_cores': cpu_count,
        'cpu_freq_mhz': cpu_freq.current if cpu_freq else 0
    }
    
    return info


def print_system_info():
    """–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ"""
    try:
        info = check_system_resources()
        
        print("üñ•Ô∏è  –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –°–ò–°–¢–ï–ú–ï")
        print("=" * 40)
        print(f"GPU: {info['gpu_name']}")
        if info['gpu_available']:
            print(f"GPU –ø–∞–º—è—Ç—å: {info['gpu_memory_gb']:.1f} GB")
        print(f"RAM: {info['ram_available_gb']:.1f} GB / {info['ram_total_gb']:.1f} GB")
        print(f"CPU: {info['cpu_cores']} —è–¥–µ—Ä @ {info['cpu_freq_mhz']:.0f} MHz")
        print("=" * 40)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if info['gpu_available'] and info['gpu_memory_gb'] >= 4:
            print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ –¥–ª—è –∫–æ–ª–æ—Ä–∏–∑–∞—Ü–∏–∏ –≤–∏–¥–µ–æ")
        elif info['ram_available_gb'] >= 8:
            print("‚ö†Ô∏è  GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω CPU (–º–µ–¥–ª–µ–Ω–Ω–µ–µ)")
        else:
            print("‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
        
    except ImportError:
        print("‚ö†Ô∏è  –ú–æ–¥—É–ª—å psutil –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–∏—Å—Ç–µ–º—ã")


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ç–∏–ª–∏—Ç
    print("üîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Ç–∏–ª–∏—Ç...")
    print_system_info()